{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8489f-c119-4666-8ced-edb09b01b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60404efb",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import RichProgressBar\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sav.datamodule import DatamoduleSAV\n",
    "from sav.module.fs_segmenter import FewShotSegmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cc447",
   "metadata": {},
   "source": [
    "# Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe56d8f-a9ee-46aa-911c-493dee5480d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(# checkpoint\n",
    "            seed=0, \n",
    "            num_epoch=1,\n",
    "            checkpoint_path='results/test',\n",
    "            model_name='test',\n",
    "            version='0',\n",
    "            precision_for_training=16,\n",
    "    \n",
    "            # model\n",
    "            backbone='vgg16', \n",
    "            optimizer='adam', \n",
    "            learning_rate=1e-4, \n",
    "            weight_decay=1e-5,\n",
    "    \n",
    "            # datamodule\n",
    "            datapath='demo_data/train',\n",
    "            nshot=3,\n",
    "            nsamples=500,\n",
    "            contrast=(0.5,1.5),\n",
    "            rotation_degrees=90.0,\n",
    "            scale=(0.25,1.0),\n",
    "            crop_size=256,\n",
    "            val_data_ratio=0.15,\n",
    "            batch_size=5,\n",
    "            n_cpu=4,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1fb02",
   "metadata": {},
   "source": [
    "# Initialise logger and callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec96cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Logger\n",
    "# logger = WandbLogger(save_dir=\"lightning_logs\",\n",
    "#                      project=\"slice-and-view_avgpool\"\n",
    "#                      )\n",
    "\n",
    "# Set checkpoints paths\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "                            save_top_k=5,\n",
    "                            monitor=\"val/val_loss\",\n",
    "                            mode=\"min\",\n",
    "                            dirpath=args['checkpoint_path'],\n",
    "                            filename= args['model_name'] + \"-{epoch:02d}\",\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52cd91",
   "metadata": {},
   "source": [
    "# Initialise datamodule and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee64a3f-fb44-4392-9016-37b9cbde09f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(args['seed'])\n",
    "\n",
    "datamodule = DatamoduleSAV(datapath=args['datapath'],\n",
    "                           nshot=args['nshot'],\n",
    "                           nsamples=args['nsamples'],\n",
    "                           contrast=args['contrast'],\n",
    "                           rotation_degrees=args['rotation_degrees'],\n",
    "                           scale=args['scale'],\n",
    "                           crop_size=args['crop_size'],\n",
    "                           val_data_ratio=args['val_data_ratio'],\n",
    "                           batch_size=args['batch_size'],\n",
    "                           n_cpu=args['n_cpu'])\n",
    "\n",
    "model = FewShotSegmenter(backbone=args['backbone'],\n",
    "                         optimizer=args['optimizer'],\n",
    "                         learning_rate=args['learning_rate'],\n",
    "                         weight_decay=args['weight_decay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affc202",
   "metadata": {},
   "source": [
    "# Initialise trainer and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=args['num_epoch'], \n",
    "                     callbacks=[RichProgressBar(),checkpoint_callback],\n",
    "                    #  logger=logger, \n",
    "                     precision=args['precision_for_training'],\n",
    "                     accelerator='gpu', \n",
    "                     devices=1)\n",
    "\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94a394",
   "metadata": {},
   "source": [
    "# Load model checkpoint from the checkpoint (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065fe96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FewShotSegmenter(backbone=args['backbone'],\n",
    "                         optimizer=args['optimizer'],\n",
    "                         learning_rate=args['learning_rate'],\n",
    "                         weight_decay=args['weight_decay']\n",
    "                        ).load_from_checkpoint('results/test/checkpoints/test/last.ckpt') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e22f44",
   "metadata": {},
   "source": [
    "# Segment a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfa3f3-b1ab-4f57-a380-a8d63acccf42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sav.utils.annotator import Annotator\n",
    "from torchvision import transforms\n",
    "\n",
    "model.to(device=\"cuda\")\n",
    "annotator = Annotator(model=model.to(device=\"cuda\"),\n",
    "                      down_sampling=4,\n",
    "                      patch_width= 224,\n",
    "                      patch_height= 224,\n",
    "                      margin=32,\n",
    "                      batch_size= 1,\n",
    "                      keep_dim=True)\n",
    "\n",
    "out = annotator(query_img_path = \"demo_data/evaluation/query_set/A3D_cauliflower_0001-NLM0001.tiff\",\n",
    "                support_imgs_dir = \"demo_data/evaluation/support_set/cauliflower/image\",\n",
    "                support_annots_dir = \"demo_data/evaluation/support_set/cauliflower/annotation\",\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69a1bf-fa8b-4501-bec5-1b21d85efaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(4,3),dpi=300)\n",
    "axs.imshow(out['raw'],cmap='gray')\n",
    "axs.imshow(np.where(out['annot']>0.5,1,0), alpha=0.3, cmap='cividis')\n",
    "axs.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
